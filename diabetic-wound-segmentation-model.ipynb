{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7200157,"sourceType":"datasetVersion","datasetId":4124555},{"sourceId":7645725,"sourceType":"datasetVersion","datasetId":4456670}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nfrom tqdm import tqdm\nimport cv2\nimport itertools\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import backend as K\n\nfrom sklearn.metrics import confusion_matrix\n\n# Set matplotlib to display plots inline in Jupyter notebooks\n%matplotlib inline ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-19T04:05:01.334801Z","iopub.execute_input":"2025-06-19T04:05:01.335016Z","iopub.status.idle":"2025-06-19T04:05:17.258939Z","shell.execute_reply.started":"2025-06-19T04:05:01.334994Z","shell.execute_reply":"2025-06-19T04:05:17.258387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom glob import glob\n\nTRAIN_IMAGE_DIR = '/kaggle/input/wound-segmentation-images/data_wound_seg/train_images'\nTRAIN_MASK_DIR = '/kaggle/input/wound-segmentation-images/data_wound_seg/train_masks'\nTEST_IMAGE_DIR = '/kaggle/input/wound-segmentation-images/data_wound_seg/test_images'\nTEST_MASK_DIR = '/kaggle/input/wound-segmentation-images/data_wound_seg/test_masks'\nCORRESPONDENCE_TABLE_PATH = '/kaggle/input/wound-segmentation-images/data_wound_seg/correspondence_table.xlsx'\n\ndef get_file_paths(image_dir, mask_dir, file_extension='*.png'):\n    \"\"\"\n    Retrieves sorted lists of image and mask file paths from the specified directories.\n\n    Args:\n        image_dir (str): Directory containing image files.\n        mask_dir (str): Directory containing mask files.\n        file_extension (str): File extension to filter files (default is '*.png').\n\n    Returns:\n        tuple: Two lists containing sorted image paths and mask paths.\n    \"\"\"\n    images = sorted(glob(os.path.join(image_dir, file_extension)))\n    masks = sorted(glob(os.path.join(mask_dir, file_extension)))\n    return images, masks\n\ndef validate_dataset(images, masks, dataset_name):\n    \"\"\"\n    Validates that the number of images and masks match and prints the count.\n\n    Args:\n        images (list): List of image file paths.\n        masks (list): List of mask file paths.\n        dataset_name (str): Name of the dataset (e.g., 'training', 'testing').\n\n    Raises:\n        ValueError: If the number of images and masks do not match.\n    \"\"\"\n    if len(images) != len(masks):\n        raise ValueError(f\"Mismatch in {dataset_name} dataset: {len(images)} images vs {len(masks)} masks.\")\n    print(f\"Number of {dataset_name} images: {len(images)}\")\n    print(f\"Number of {dataset_name} masks: {len(masks)}\")\n\n# Get file paths for training and testing datasets\ntrain_images, train_masks = get_file_paths(TRAIN_IMAGE_DIR, TRAIN_MASK_DIR)\ntest_images, test_masks = get_file_paths(TEST_IMAGE_DIR, TEST_MASK_DIR)\n\n# Validate and print dataset sizes\nvalidate_dataset(train_images, train_masks, 'training')\nvalidate_dataset(test_images, test_masks, 'testing')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T04:06:00.858503Z","iopub.execute_input":"2025-06-19T04:06:00.859060Z","iopub.status.idle":"2025-06-19T04:06:00.878009Z","shell.execute_reply.started":"2025-06-19T04:06:00.859034Z","shell.execute_reply":"2025-06-19T04:06:00.877441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\n\ndef display_samples(images, masks, num_samples=5):\n    \"\"\"\n    Displays a sample of images and their corresponding masks side by side.\n\n    Args:\n        images (list): List of paths to image files.\n        masks (list): List of paths to mask files.\n        num_samples (int): Number of samples to display (default is 5).\n\n    Raises:\n        ValueError: If the number of images and masks do not match.\n    \"\"\"\n    if len(images) != len(masks):\n        raise ValueError(\"The number of images and masks must be the same.\")\n\n    # Set up the figure for visualization\n    plt.figure(figsize=(12, num_samples * 4))\n\n    for i in range(num_samples):\n        # Load and preprocess the image\n        img = cv2.imread(images[i])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct display\n\n        # Load the mask in grayscale\n        mask = cv2.imread(masks[i], cv2.IMREAD_GRAYSCALE)\n\n        # Display the image\n        plt.subplot(num_samples, 2, 2 * i + 1)\n        plt.imshow(img)\n        plt.title(f'Image {i + 1}')\n        plt.axis('off')\n\n        # Display the corresponding mask\n        plt.subplot(num_samples, 2, 2 * i + 2)\n        plt.imshow(mask, cmap='gray')\n        plt.title(f'Mask {i + 1}')\n        plt.axis('off')\n\n    # Adjust layout for better visualization\n    plt.tight_layout()\n    plt.show()\n\n# Example usage: Display 3 samples from the training set\ndisplay_samples(train_images, train_masks, num_samples=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T04:06:35.826652Z","iopub.execute_input":"2025-06-19T04:06:35.826948Z","iopub.status.idle":"2025-06-19T04:06:36.637761Z","shell.execute_reply.started":"2025-06-19T04:06:35.826926Z","shell.execute_reply":"2025-06-19T04:06:36.637009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom tensorflow.keras.utils import Sequence\n\n# Constants for configuration\nIMG_HEIGHT = 256  # Target image height\nIMG_WIDTH = 256   # Target image width\nBATCH_SIZE = 16   # Batch size for training\nNORMALIZE_FACTOR = 255.0  # Normalization factor for pixel values\n\nclass DataGenerator(Sequence):\n    \"\"\"\n    Custom data generator for loading and augmenting images and masks in batches.\n\n    Args:\n        image_filenames (list): List of paths to image files.\n        mask_filenames (list): List of paths to mask files.\n        batch_size (int): Number of samples per batch.\n        img_height (int): Target height for resizing images and masks.\n        img_width (int): Target width for resizing images and masks.\n        augment (bool): Whether to apply data augmentation (default is False).\n    \"\"\"\n\n    def __init__(self, image_filenames, mask_filenames, batch_size, img_height, img_width, augment=False):\n        self.image_filenames = image_filenames\n        self.mask_filenames = mask_filenames\n        self.batch_size = batch_size\n        self.img_height = img_height\n        self.img_width = img_width\n        self.augment = augment\n\n    def __len__(self):\n        \"\"\"Returns the number of batches per epoch.\"\"\"\n        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n\n    def __getitem__(self, idx):\n        \"\"\"Generates one batch of data.\"\"\"\n        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.mask_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        images, masks = [], []\n        for img_path, mask_path in zip(batch_x, batch_y):\n            img = self._load_and_preprocess_image(img_path)\n            mask = self._load_and_preprocess_mask(mask_path)\n\n            if self.augment:\n                img, mask = self._apply_augmentation(img, mask)\n\n            images.append(img)\n            masks.append(mask)\n\n        return np.array(images), np.array(masks)\n\n    def _load_and_preprocess_image(self, img_path):\n        \"\"\"Loads and preprocesses an image.\"\"\"\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n        img = cv2.resize(img, (self.img_width, self.img_height))  # Resize\n        img = img / NORMALIZE_FACTOR  # Normalize to [0, 1]\n        img = img.astype(np.float32)  # Cast to float32\n        return img\n\n    def _load_and_preprocess_mask(self, mask_path):\n        \"\"\"Loads and preprocesses a mask.\"\"\"\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Read in grayscale\n        mask = cv2.resize(mask, (self.img_width, self.img_height))  # Resize\n        mask = np.expand_dims(mask, axis=-1)  # Add channel dimension\n        mask = mask / NORMALIZE_FACTOR  # Normalize to [0, 1]\n        mask = mask.astype(np.float32)  # Cast to float32\n        return mask\n\n    def _apply_augmentation(self, img, mask):\n        \"\"\"Applies random augmentation to an image and its mask.\"\"\"\n        # Random horizontal flip\n        if np.random.rand() > 0.5:\n            img = np.fliplr(img)\n            mask = np.fliplr(mask)\n\n        # Random vertical flip\n        if np.random.rand() > 0.5:\n            img = np.flipud(img)\n            mask = np.flipud(mask)\n\n        # Random rotation\n        angle = np.random.randint(-15, 15)\n        M = cv2.getRotationMatrix2D((self.img_width / 2, self.img_height / 2), angle, 1)\n        img = cv2.warpAffine(img, M, (self.img_width, self.img_height)).astype(np.float32)\n        mask = cv2.warpAffine(mask, M, (self.img_width, self.img_height)).astype(np.float32)\n\n        return img, mask\n\n# Create data generators\ntrain_generator = DataGenerator(train_images, train_masks, BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH, augment=True)\ntest_generator = DataGenerator(test_images, test_masks, BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T04:06:44.668080Z","iopub.execute_input":"2025-06-19T04:06:44.668352Z","iopub.status.idle":"2025-06-19T04:06:44.679844Z","shell.execute_reply.started":"2025-06-19T04:06:44.668331Z","shell.execute_reply":"2025-06-19T04:06:44.679085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom tensorflow.keras.utils import Sequence\n\nclass DataGenerator(Sequence):\n    \"\"\"\n    Custom data generator for loading and augmenting images and masks in batches.\n\n    Args:\n        image_filenames (list): List of paths to image files.\n        mask_filenames (list): List of paths to mask files.\n        batch_size (int): Number of samples per batch.\n        img_height (int): Target height for resizing images and masks.\n        img_width (int): Target width for resizing images and masks.\n        augment (bool): Whether to apply data augmentation (default is False).\n    \"\"\"\n\n    def __init__(self, image_filenames, mask_filenames, batch_size, img_height, img_width, augment=False):\n        self.image_filenames = image_filenames\n        self.mask_filenames = mask_filenames\n        self.batch_size = batch_size\n        self.img_height = img_height\n        self.img_width = img_width\n        self.augment = augment\n\n    def __len__(self):\n        \"\"\"Returns the number of batches per epoch.\"\"\"\n        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n\n    def __getitem__(self, idx):\n        \"\"\"Generates one batch of data.\"\"\"\n        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.mask_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        images, masks = [], []\n        for img_path, mask_path in zip(batch_x, batch_y):\n            img = self._load_and_preprocess_image(img_path)\n            mask = self._load_and_preprocess_mask(mask_path)\n\n            if self.augment:\n                img, mask = self._apply_augmentation(img, mask)\n\n            images.append(img)\n            masks.append(mask)\n\n        return np.array(images), np.array(masks)\n\n    def _load_and_preprocess_image(self, img_path):\n        \"\"\"Loads and preprocesses an image.\"\"\"\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n        img = cv2.resize(img, (self.img_width, self.img_height))  # Resize\n        img = img / 255.0  # Normalize to [0, 1]\n        return img\n\n    def _load_and_preprocess_mask(self, mask_path):\n        \"\"\"Loads and preprocesses a mask.\"\"\"\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Read in grayscale\n        mask = cv2.resize(mask, (self.img_width, self.img_height))  # Resize\n        mask = np.expand_dims(mask, axis=-1)  # Add channel dimension\n        mask = mask / 255.0  # Normalize to [0, 1]\n        return mask\n\n    def _apply_augmentation(self, img, mask):\n        \"\"\"Applies random augmentation to an image and its mask.\"\"\"\n        # Random horizontal flip\n        if np.random.rand() > 0.5:\n            img = np.fliplr(img)\n            mask = np.fliplr(mask)\n\n        # Random vertical flip\n        if np.random.rand() > 0.5:\n            img = np.flipud(img)\n            mask = np.flipud(mask)\n\n        # Random rotation\n        angle = np.random.randint(-15, 15)\n        M = cv2.getRotationMatrix2D((self.img_width / 2, self.img_height / 2), angle, 1)\n        img = cv2.warpAffine(img, M, (self.img_width, self.img_height))\n        mask = cv2.warpAffine(mask, M, (self.img_width, self.img_height))\n\n        return img, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T04:06:50.198516Z","iopub.execute_input":"2025-06-19T04:06:50.199201Z","iopub.status.idle":"2025-06-19T04:06:50.208600Z","shell.execute_reply.started":"2025-06-19T04:06:50.199166Z","shell.execute_reply":"2025-06-19T04:06:50.208024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dropout, MaxPooling2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.models import Model\n\ndef unet_model(input_size=(256, 256, 3)):\n    \"\"\"\n    Defines a U-Net model for image segmentation.\n\n    Args:\n        input_size (tuple): Input image dimensions (height, width, channels). Default is (256, 256, 3).\n\n    Returns:\n        model (tf.keras.Model): A U-Net model.\n    \"\"\"\n    inputs = Input(input_size)\n\n    # Encoder (Downsampling Path)\n    def encoder_block(input_tensor, filters, dropout_rate):\n        \"\"\"Creates an encoder block with two convolutional layers, batch normalization, and dropout.\"\"\"\n        x = Conv2D(filters, (3, 3), activation='relu', padding='same')(input_tensor)\n        x = BatchNormalization()(x)\n        x = Dropout(dropout_rate)(x)\n        x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n        p = MaxPooling2D((2, 2))(x)\n        return x, p\n\n    c1, p1 = encoder_block(inputs, 64, 0.1)\n    c2, p2 = encoder_block(p1, 128, 0.1)\n    c3, p3 = encoder_block(p2, 256, 0.2)\n    c4, p4 = encoder_block(p3, 512, 0.2)\n\n    # Bridge\n    bridge = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n    bridge = BatchNormalization()(bridge)\n    bridge = Dropout(0.3)(bridge)\n    bridge = Conv2D(1024, (3, 3), activation='relu', padding='same')(bridge)\n\n    # Decoder (Upsampling Path)\n    def decoder_block(input_tensor, skip_tensor, filters, dropout_rate):\n        \"\"\"Creates a decoder block with upsampling, concatenation, and two convolutional layers.\"\"\"\n        x = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n        x = concatenate([x, skip_tensor])\n        x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(dropout_rate)(x)\n        x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n        return x\n\n    d1 = decoder_block(bridge, c4, 512, 0.2)\n    d2 = decoder_block(d1, c3, 256, 0.2)\n    d3 = decoder_block(d2, c2, 128, 0.1)\n    d4 = decoder_block(d3, c1, 64, 0.1)\n\n    # Output Layer\n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(d4)\n\n    # Create the model\n    model = Model(inputs=[inputs], outputs=[outputs])\n    return model\n\n# Instantiate the model\nmodel = unet_model()\n\n# Print the model summary\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T04:06:55.578146Z","iopub.execute_input":"2025-06-19T04:06:55.578397Z","iopub.status.idle":"2025-06-19T04:06:58.319343Z","shell.execute_reply.started":"2025-06-19T04:06:55.578380Z","shell.execute_reply":"2025-06-19T04:06:58.318663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\ndef dice_coefficient(y_true, y_pred, smooth=1):\n    \"\"\"\n    Computes the Dice Coefficient, a metric for evaluating segmentation performance.\n\n    Args:\n        y_true (tensor): Ground truth labels.\n        y_pred (tensor): Predicted labels.\n        smooth (float): Smoothing factor to avoid division by zero. Default is 1.\n\n    Returns:\n        dice (tensor): Dice Coefficient score.\n    \"\"\"\n    # Flatten and cast tensors to float32\n    y_true_f = K.flatten(K.cast(y_true, 'float32'))\n    y_pred_f = K.flatten(K.cast(y_pred, 'float32'))\n\n    # Compute intersection and Dice Coefficient\n    intersection = K.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return dice\n\ndef iou_metric(y_true, y_pred, smooth=1):\n    \"\"\"\n    Computes the Intersection over Union (IoU), a metric for evaluating segmentation performance.\n\n    Args:\n        y_true (tensor): Ground truth labels.\n        y_pred (tensor): Predicted labels.\n        smooth (float): Smoothing factor to avoid division by zero. Default is 1.\n\n    Returns:\n        iou (tensor): IoU score.\n    \"\"\"\n    # Flatten and cast tensors to float32\n    y_true_f = K.flatten(K.cast(y_true, 'float32'))\n    y_pred_f = K.flatten(K.cast(y_pred, 'float32'))\n\n    # Compute intersection and union\n    intersection = K.sum(y_true_f * y_pred_f)\n    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n\n    # Compute IoU\n    iou = (intersection + smooth) / (union + smooth)\n    return iou","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T04:07:29.198471Z","iopub.execute_input":"2025-06-19T04:07:29.198958Z","iopub.status.idle":"2025-06-19T04:07:29.205573Z","shell.execute_reply.started":"2025-06-19T04:07:29.198933Z","shell.execute_reply":"2025-06-19T04:07:29.205014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-4),  \n    loss='binary_crossentropy',          \n    metrics=[\n        'accuracy',                     \n        dice_coefficient,                \n        iou_metric     \n    ] \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T04:07:35.378420Z","iopub.execute_input":"2025-06-19T04:07:35.378993Z","iopub.status.idle":"2025-06-19T04:07:35.392401Z","shell.execute_reply.started":"2025-06-19T04:07:35.378969Z","shell.execute_reply":"2025-06-19T04:07:35.391865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\n\n# Define custom metrics\ndef dice_coefficient(y_true, y_pred, smooth=1):\n    y_true_f = tf.keras.backend.flatten(y_true)\n    y_pred_f = tf.keras.backend.flatten(y_pred)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n\ndef iou_metric(y_true, y_pred, smooth=1):\n    y_true_f = tf.keras.backend.flatten(y_true)\n    y_pred_f = tf.keras.backend.flatten(y_pred)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n    return (intersection + smooth) / (union + smooth)\n\n# Callbacks for training\ndef get_callbacks(): \n    \"\"\"\n    Creates and returns a list of callbacks for model training.\n\n    Returns:\n        list: A list of callbacks including ModelCheckpoint, EarlyStopping, and ReduceLROnPlateau.\n    \"\"\"\n    checkpoint = ModelCheckpoint(\n        'unet_wound_segmentation_best.keras',\n        monitor='val_loss',\n        save_best_only=True,\n        verbose=1,\n        mode='min'\n    )\n\n    earlystop = EarlyStopping(\n        monitor='val_loss',\n        patience=15,\n        verbose=1,\n        restore_best_weights=True\n    )\n\n    reduce_lr = ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=7,\n        verbose=1,\n        mode='min',\n        min_lr=1e-6\n    )\n\n    return [checkpoint, earlystop, reduce_lr]\n\n# Compile the model\ndef compile_model(model):\n    \"\"\"\n    Compiles the model with Adam optimizer, binary cross-entropy loss, and custom metrics.\n\n    Args:\n        model (tf.keras.Model): The model to compile.\n    \"\"\"\n    model.compile(\n        optimizer=Adam(learning_rate=1e-4),\n        loss='binary_crossentropy',\n        metrics=['accuracy', dice_coefficient, iou_metric]\n    )\n\n# Train the model\ndef train_model(model, train_generator, test_generator, epochs=50):\n    \"\"\"\n    Trains the model using the provided data generators and callbacks.\n\n    Args:\n        model (tf.keras.Model): The model to train.\n        train_generator (DataGenerator): Training data generator.\n        test_generator (DataGenerator): Validation data generator.\n        epochs (int): Number of training epochs. Default is 100.\n\n    Returns:\n        history: Training history object.\n    \"\"\"\n    callbacks_list = get_callbacks()\n\n    history = model.fit(\n        train_generator,\n        validation_data=test_generator,\n        epochs=epochs,\n        callbacks=callbacks_list,\n        verbose=1\n    )\n    return history\n\n# === Example Usage ===\n# Assuming you have `model`, `train_generator`, and `test_generator` already defined\n\ncompile_model(model)\nhistory = train_model(model, train_generator, test_generator, epochs=100)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T04:07:50.479882Z","iopub.execute_input":"2025-06-19T04:07:50.480335Z","iopub.status.idle":"2025-06-19T07:14:58.172475Z","shell.execute_reply.started":"2025-06-19T04:07:50.480312Z","shell.execute_reply":"2025-06-19T07:14:58.171895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt  \n\ndef plot_training_history(history):\n    \"\"\"\n    Plots the training and validation accuracy and loss over epochs\n\n    Args: \n        history (tf.keras.callbacks.History): The history object returned by model. fit.\n\n    Returns:\n        None\n    \"\"\"\n    # Extract metrics from the history object\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(acc) + 1)\n     \n    # Plot training and validation accuracy\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'bo-', label='Training Accuracy')\n    plt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Plot training and validation loss\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'bo-', label='Training Loss')\n    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n# Example usage\nplot_training_history(history)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:16:04.699585Z","iopub.execute_input":"2025-06-19T07:16:04.700433Z","iopub.status.idle":"2025-06-19T07:16:05.159879Z","shell.execute_reply.started":"2025-06-19T07:16:04.700400Z","shell.execute_reply":"2025-06-19T07:16:05.159126Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict on the test dataset\ntest_predictions = model.predict(test_generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:17:05.888507Z","iopub.execute_input":"2025-06-19T07:17:05.889064Z","iopub.status.idle":"2025-06-19T07:17:19.376525Z","shell.execute_reply.started":"2025-06-19T07:17:05.889042Z","shell.execute_reply":"2025-06-19T07:17:19.375915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on the test data\ntest_loss, test_accuracy, test_dice, test_iou = model.evaluate(test_generator, verbose=1)\n\n# Print the test accuracy\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:17:32.502017Z","iopub.execute_input":"2025-06-19T07:17:32.502755Z","iopub.status.idle":"2025-06-19T07:17:43.096294Z","shell.execute_reply.started":"2025-06-19T07:17:32.502731Z","shell.execute_reply":"2025-06-19T07:17:43.095752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_training_history(history, test_accuracy=None):\n    \"\"\"\n    Plots the training and validation accuracy and loss over epochs.\n    Optionally, adds a horizontal line for Test Accuracy.\n\n    Args:\n        history (tf.keras.callbacks.History): The history object returned by model.fit.\n        test_accuracy (float): Test accuracy to display on the plot (optional).\n\n    Returns:\n        None\n    \"\"\"\n    # Extract metrics from the history object\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(acc) + 1)  # Epochs for the x-axis\n\n    # Plot training and validation accuracy\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'bo-', label='Training Accuracy')\n    plt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n    \n    # Add Test Accuracy as a horizontal line\n    if test_accuracy is not None:\n        plt.axhline(y=test_accuracy, color='g', linestyle='--', label=f'Test Accuracy: {test_accuracy:.4f}')\n    \n    plt.title('Training, Validation, and Test Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Plot training and validation loss\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'bo-', label='Training Loss')\n    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n#Evaluate the model on the test data\ntest_loss, test_accuracy, test_dice, test_iou = model.evaluate(test_generator, verbose=1)\n\n# Print the test accuracy\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Dice Coefficient: {test_dice:.4f}\")\nprint(f\"Test IoU: {test_iou:.4f}\")\n\n# Plot training history with Test Accuracy\nplot_training_history(history, test_accuracy) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:19:45.744219Z","iopub.status.idle":"2025-06-19T07:19:45.744490Z","shell.execute_reply.started":"2025-06-19T07:19:45.744371Z","shell.execute_reply":"2025-06-19T07:19:45.744383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the model in .h5 format\nmodel.save('unet_wound_segmentation_model.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:20:13.382979Z","iopub.execute_input":"2025-06-19T07:20:13.383508Z","iopub.status.idle":"2025-06-19T07:20:14.179289Z","shell.execute_reply.started":"2025-06-19T07:20:13.383485Z","shell.execute_reply":"2025-06-19T07:20:14.178420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\n# 1. Get true masks and predictions (same as before)\ndef get_true_and_predicted_masks(generator, model):\n    true_masks = []\n    predicted_masks = []\n    \n    for i in tqdm(range(len(generator))):\n        batch_images, batch_masks = generator[i]\n        batch_preds = model.predict(batch_images, verbose=0)\n        true_masks.append(batch_masks)\n        predicted_masks.append(batch_preds)\n    \n    return np.concatenate(true_masks), np.concatenate(predicted_masks)\n\ntrue_masks, pred_masks = get_true_and_predicted_masks(test_generator, model)\n\n# 2. Threshold and convert to integers\nthreshold = 0.5\nbinary_preds = (pred_masks > threshold).astype(np.int8)  # Convert to integers\nbinary_true = (true_masks > threshold).astype(np.int8)   # Ensure ground truth is also binary\n\n# 3. Flatten arrays\ny_true = binary_true.flatten()\ny_pred = binary_preds.flatten()\n\n# 4. Calculate metrics\nprecision = precision_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred)\nf1 = f1_score(y_true, y_pred)\n\n# 5. Get other metrics from model evaluation\ntest_loss, test_acc, test_dice, test_iou = model.evaluate(test_generator, verbose=0)\n\n# 6. Create report\nreport = {\n    \"Test Accuracy\": f\"{test_acc:.4f}\",\n    \"Test Dice Coefficient\": f\"{test_dice:.4f}\",\n    \"Test IoU\": f\"{test_iou:.4f}\",\n    \"Precision\": f\"{precision:.4f}\",\n    \"Recall\": f\"{recall:.4f}\",\n    \"F1 Score\": f\"{f1:.4f}\"\n}\n\n# 7. Print formatted report\nprint(\"Model Performance Report:\")\nprint(\"=\"*40)\nfor metric, value in report.items():\n    print(f\"{metric:20}: {value}\")\nprint(\"=\"*40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:21:01.862199Z","iopub.execute_input":"2025-06-19T07:21:01.862786Z","iopub.status.idle":"2025-06-19T07:22:21.626078Z","shell.execute_reply.started":"2025-06-19T07:21:01.862762Z","shell.execute_reply":"2025-06-19T07:22:21.625389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-segmentation-images/data_wound_seg/test_images/fusc_0021.png'  \ndisplay_prediction(test_image_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:24:48.659257Z","iopub.execute_input":"2025-06-19T07:24:48.659944Z","iopub.status.idle":"2025-06-19T07:24:55.119116Z","shell.execute_reply.started":"2025-06-19T07:24:48.659920Z","shell.execute_reply":"2025-06-19T07:24:55.118334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-segmentation-images/data_wound_seg/test_images/fusc_0024.png'  \ndisplay_prediction(test_image_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:25:04.427176Z","iopub.execute_input":"2025-06-19T07:25:04.427740Z","iopub.status.idle":"2025-06-19T07:25:06.410560Z","shell.execute_reply.started":"2025-06-19T07:25:04.427715Z","shell.execute_reply":"2025-06-19T07:25:06.409511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-segmentation-images/data_wound_seg/test_images/fusc_0030.png'  \ndisplay_prediction(test_image_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:25:14.943773Z","iopub.execute_input":"2025-06-19T07:25:14.944135Z","iopub.status.idle":"2025-06-19T07:25:16.967988Z","shell.execute_reply.started":"2025-06-19T07:25:14.944107Z","shell.execute_reply":"2025-06-19T07:25:16.967307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-classification/Wound_dataset copy/Abrasions/abrasions (10).jpg'  \ndisplay_prediction(test_image_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:25:23.083113Z","iopub.execute_input":"2025-06-19T07:25:23.083409Z","iopub.status.idle":"2025-06-19T07:25:25.091830Z","shell.execute_reply.started":"2025-06-19T07:25:23.083389Z","shell.execute_reply":"2025-06-19T07:25:25.090989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-classification/Wound_dataset copy/Pressure Wounds/mirrored_sloughy-pressure-ulcer-0038.jpg'  \ndisplay_prediction(test_image_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:25:34.288171Z","iopub.execute_input":"2025-06-19T07:25:34.288796Z","iopub.status.idle":"2025-06-19T07:25:36.670807Z","shell.execute_reply.started":"2025-06-19T07:25:34.288775Z","shell.execute_reply":"2025-06-19T07:25:36.669985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-classification/Wound_dataset copy/Diabetic Wounds/103_0.jpg'  \ndisplay_prediction(test_image_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:49:31.650516Z","iopub.execute_input":"2025-06-19T07:49:31.650908Z","iopub.status.idle":"2025-06-19T07:49:34.142364Z","shell.execute_reply.started":"2025-06-19T07:49:31.650885Z","shell.execute_reply":"2025-06-19T07:49:34.141689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-classification/Wound_dataset copy/Surgical Wounds/109_0.jpg'  \ndisplay_prediction(test_image_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:25:52.302247Z","iopub.execute_input":"2025-06-19T07:25:52.302551Z","iopub.status.idle":"2025-06-19T07:25:55.035190Z","shell.execute_reply.started":"2025-06-19T07:25:52.302530Z","shell.execute_reply":"2025-06-19T07:25:55.034504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-classification/Wound_dataset copy/Surgical Wounds/100_0.jpg'  \ndisplay_prediction(test_image_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:26:04.502551Z","iopub.execute_input":"2025-06-19T07:26:04.502869Z","iopub.status.idle":"2025-06-19T07:26:06.506835Z","shell.execute_reply.started":"2025-06-19T07:26:04.502847Z","shell.execute_reply":"2025-06-19T07:26:06.505992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-classification/Wound_dataset copy/Diabetic Wounds/110_0.jpg'  \ndisplay_prediction(test_image_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T08:02:02.926454Z","iopub.execute_input":"2025-06-19T08:02:02.926778Z","iopub.status.idle":"2025-06-19T08:02:04.847147Z","shell.execute_reply.started":"2025-06-19T08:02:02.926757Z","shell.execute_reply":"2025-06-19T08:02:04.846351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-classification/Wound_dataset copy/Venous Wounds/110_0.jpg'  \ndisplay_prediction(test_image_path, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:26:21.643092Z","iopub.execute_input":"2025-06-19T07:26:21.643686Z","iopub.status.idle":"2025-06-19T07:26:23.657332Z","shell.execute_reply.started":"2025-06-19T07:26:21.643651Z","shell.execute_reply":"2025-06-19T07:26:23.656543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_confusion_matrix(model, test_generator, threshold=0.5):\n    \"\"\"\n    Generates a confusion matrix for segmentation results.\n    \n    Args:\n        model: Trained model\n        test_generator: Test data generator\n        threshold: Threshold for binary classification of pixels\n    \n    Returns:\n        cm: Confusion matrix as [[TN, FP], [FN, TP]]\n    \"\"\"\n    # Initialize counters\n    TN, FP, FN, TP = 0, 0, 0, 0\n\n    # Process all test data\n    for i in tqdm(range(len(test_generator))):\n        batch_images, batch_masks = test_generator[i]\n        pred_masks = model.predict(batch_images, verbose=0)\n        \n        # Threshold predictions and flatten\n        y_true = batch_masks.flatten() > 0.5\n        y_pred = pred_masks.flatten() > threshold\n\n        # Update confusion matrix counts\n        TN += np.sum((y_pred == False) & (y_true == False))\n        FP += np.sum((y_pred == True) & (y_true == False))\n        FN += np.sum((y_pred == False) & (y_true == True))\n        TP += np.sum((y_pred == True) & (y_true == True))\n\n    return np.array([[TN, FP], [FN, TP]])\n\ndef plot_confusion_matrix(cm, class_names=['Background', 'Wound']):\n    \"\"\"\n    Plots a confusion matrix using seaborn heatmap.\n    \n    Args:\n        cm: Confusion matrix array\n        class_names: List of class names\n    \"\"\"\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show()\n\n    # Calculate metrics\n    accuracy = (cm[0,0] + cm[1,1]) / cm.sum()\n    precision = cm[1,1] / (cm[1,1] + cm[0,1])\n    recall = cm[1,1] / (cm[1,1] + cm[1,0])\n    dice = (2 * cm[1,1]) / (2 * cm[1,1] + cm[0,1] + cm[1,0])\n\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall/Sensitivity: {recall:.4f}\")\n    print(f\"Dice Coefficient: {dice:.4f}\")\n\n# Generate and plot confusion matrix\ncm = generate_confusion_matrix(model, test_generator)\nplot_confusion_matrix(cm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T07:26:34.262410Z","iopub.execute_input":"2025-06-19T07:26:34.262974Z","iopub.status.idle":"2025-06-19T07:26:55.646684Z","shell.execute_reply.started":"2025-06-19T07:26:34.262953Z","shell.execute_reply":"2025-06-19T07:26:55.645823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('unet_wound_segmentation_model.h5', custom_objects={'dice_coefficient': dice_coefficient, 'iou_metric': iou_metric})\n\ndef preprocess_image(image_path, target_size=(256, 256)):\n    \"\"\"\n    Load and preprocess an image for prediction.\n\n    Args:\n        image_path (str): Path to the image file.\n        target_size (tuple): Target size for resizing the image. Default is (256, 256).\n\n    Returns:\n        np.array: Preprocessed image.\n    \"\"\"\n    # Load the image\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n    image = cv2.resize(image, target_size)  # Resize to target size\n    image = image / 255.0  # Normalize to [0, 1]\n    image = np.expand_dims(image, axis=0)  # Add batch dimension\n    return image\n\ndef display_prediction(image_path, model):\n    \"\"\"\n    Display the original image and its prediction (segmentation mask).\n\n    Args:\n        image_path (str): Path to the image file.\n        model (tf.keras.Model): Trained model for prediction.\n\n    Returns:\n        None\n    \"\"\"\n    # Preprocess the image\n    image = preprocess_image(image_path)\n\n    # Generate prediction\n    prediction = model.predict(image)\n    prediction_mask = (prediction.squeeze() > 0.5).astype(np.uint8)  # Apply threshold (0.5)\n\n    # Load the original image for display\n    original_image = cv2.imread(image_path)\n    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n\n    # Display the original image and the prediction\n    plt.figure(figsize=(10, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(original_image)\n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(prediction_mask, cmap='gray')\n    plt.title('Prediction Mask')\n    plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Test the model on a new image\ntest_image_path = '/kaggle/input/wound-classification/Wound_dataset copy/Diabetic Wounds/119_0.jpg'  \ndisplay_prediction(test_image_path, model)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T08:06:35.016544Z","iopub.execute_input":"2025-06-19T08:06:35.016869Z","iopub.status.idle":"2025-06-19T08:06:36.918449Z","shell.execute_reply.started":"2025-06-19T08:06:35.016848Z","shell.execute_reply":"2025-06-19T08:06:36.917674Z"}},"outputs":[],"execution_count":null}]}